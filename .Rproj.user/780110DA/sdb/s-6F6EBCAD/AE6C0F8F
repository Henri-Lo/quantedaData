{
    "contents" : "#' Create a document-feature matrix from a corpus object\n#'\n#' returns a document by feature matrix compatible with austin.  A typical usage would\n#' be to produce a word-frequency matrix where the cells are counts of words by document.\n#' \n#' @param corpus Corpus from which to generate the document-feature matrix\n#' @param feature Feature to count (e.g. words)\n#' @param stem Stem the words\n#' @param stopwords A character vector of stopwords that will be removed from the text when constructing the \\link{dfm}.  If \\code{NULL} (default)\n#' then no stopwords will be applied.  If \"TRUE\" then it currently defaults to \\code{\\link{stopwords}}.\n#' @param groups Grouping variable for aggregating documents\n#' @param subset Expression for subsetting the corpus before processing\n#' @param verbose Get info to screen on the progress\n#' @param dictionary A list of character vector dictionary entries, including regular expressions (see examples) \n#' @param dictionary.regex \\code{TRUE} means the dictionary is already in regular expression format,\n#' otherwise it will be converted from \"wildcard\" format\n#' @param addto \\code{NULL} by default, but if an existing dfm object is specified, then the new dfm will be added to the one named.\n#' If both \\link{dfm}'s are built from dictionaries, the combined dfm will have its \\code{Non_Dictionary} total adjusted.\n#' @return A matrix object with row names equal to the document names and column names equal to the feature labels.  \n#' This matrix has \\code{names(dimnames) = c(\"docs\", \"words\")}\n#' to make it conformable to an \\link[austin]{wfm} object.\n#' @rdname dfm\n#' @export \n#' @author Kenneth Benoit\n#' @examples \n#' data(iebudgets)\n#' wfm <- dfm(iebudgets)\n#' \n#' ## by party, subset for 2010\n#' wfmByParty2010 <- dfm(subset(iebudgets, year==2010), groups=\"party\")\n#' \n#' ## with dictionaries\n#' corpus <- subset(iebudgets, year==2010)\n#' mydict <- list(christmas=c(\"Christmas\", \"Santa\", \"holiday\"),\n#'                opposition=c(\"Opposition\", \"reject\", \"notincorpus\"),\n#'                taxing=\"taxing\",\n#'                taxation=\"taxation\",\n#'                taxregex=\"tax*\")\n#' dictDfm <- dfm(corpus, dictionary=mydict)\n#' dictDfm\n#' \n#' ## removing stopwords\n#' testText <- \"The quick brown fox named SÃ©amus jumps over the lazy dog Rory, with Tom's newpaper in his mouth.\"#\n#' testCorpus <- corpusCreate(testText)\n#' dfm(testCorpus, stopwords=TRUE)\n#' if (require(tm)) {\n#' }\n#' \n#' ## adding one dfm to another\n#' mydict2 <- list(partyref=c(\"Lenihan\", \"Fianna\", \"Sinn\", \"Gael\"))\n#' dictDfm2 <- dfm(corpus, dictionary=mydict2, addto=dictDfm)\n#' dictDfm2\ndfm <- function(corpus,\n                feature=c(\"word\"),\n                stem=FALSE,\n                stopwords=NULL,\n                bigram=FALSE,\n                groups=NULL,\n                subset=NULL, \n                verbose=TRUE, \n                dictionary=NULL,\n                dictionary.regex=FALSE,\n                addto=NULL) {\n  UseMethod(\"dfm\")\n}\n\n#' @rdname dfm\n#' @method dfm corpus\n#' @S3method dfm corpus\ndfm.corpus <- function(corpus,\n                       feature=c(\"word\"),\n                       stem=FALSE,\n                       stopwords=NULL,\n                       bigram=FALSE,\n                       groups=NULL,\n                       subset=NULL, \n                       verbose=TRUE, \n                       dictionary=NULL,\n                       dictionary.regex=FALSE,\n                       addto=NULL) {\n  if (verbose) cat(\"Creating dfm from a corpus: ... \")\n  # subsets \n  if (!is.null(subset)) corpus <- corpus.subset.inner(corpus, substitute(subset))\n  \n  # aggregation by group\n  if (!is.null(groups)) {\n    if (verbose) cat(\"aggregating by group: \", groups, \"... \", sep=\"\")\n    if (length(groups)>1) {\n      group.split <- lapply(corpus$attribs[,groups], as.factor)\n    } else group.split <- as.factor(corpus$attribs[,groups])\n    texts <- split(corpus$attribs$texts, group.split)\n    texts <- sapply(texts, paste, collapse = \" \")\n    if (verbose) cat(\"complete ...\")\n  } else {\n    texts <- corpus$attribs$texts\n    names(texts) <- rownames(corpus$attribs)\n  }\n  \n  # changing verbose to 2 (instead of TRUE) means will not print message twice\n  # when the function calls dfm.character\n  return(dfm(texts, feature=feature, stem=stem, stopwords=stopwords, bigram=bigram, \n             verbose=2, dictionary=dictionary, dictionary.regex=dictionary.regex, \n             addto=addto))\n}\n\n#' @rdname dfm\n#' @method dfm character\n#' @S3method dfm character\ndfm.character <- function(textvec,\n                          feature=c(\"word\"),\n                          stem=FALSE,\n                          stopwords=NULL,\n                          bigram=FALSE,\n                          verbose=TRUE, \n                          dictionary=NULL,\n                          dictionary.regex=FALSE,\n                          addto=NULL) {\n  # if (verbose & parent.env(dfm.character) != dfm.corpus) cat(\"Creating dfm: ...\")\n  if (verbose==TRUE) cat(\"Creating dfm from character vector ...\")\n  \n  if (is.null(names(textvec))) {\n    names(textvec) <- factor(paste(\"text\", 1:length(textvec), sep=\"\"))\n  }\n  textnames <- factor(names(textvec))\n  \n  tokenizedTexts <- sapply(textvec, tokenizeSingle, simplify=FALSE)\n  if (stem==TRUE) {\n    require(SnowballC, quietly=TRUE)\n    if (verbose) cat(\" stemming ...\")\n    tokenizedTexts <- lapply(tokenizedTexts, wordStem)\n  }\n  if (bigram > 0) {\n    if (verbose) cat(\" making bigrams ...\")\n    tokenizedTexts <- lapply(tokenizedTexts, function(x) bigrams(x, bigram))\n  }\n  \n  # get original sort order, so that we can restore original order after table \n  # alphabetizes the documents (rows of the dfm)\n  originalSortOrder <- (1:length(tokenizedTexts))[order(names(tokenizedTexts))]\n  \n  # print(length)\n  alltokens <- data.frame(docs = rep(textnames, sapply(tokenizedTexts, length)),\n                          words = unlist(tokenizedTexts, use.names=FALSE))\n  \n  # need to enforce check that dictionary is a named list\n  if (is.null(dictionary)) {\n    dfm <- as.data.frame.matrix(table(alltokens$docs, alltokens$words))\n  } else {\n    # flatten the dictionary\n    dictionary <- flatten.dictionary(dictionary)\n    # convert wildcards to regular expressions (if needed) \n    if (!dictionary.regex) {\n      dictionary <- lapply(dictionary, makeRegEx)\n    }\n    alltokens <- cbind(alltokens, \n                       matrix(0, nrow=nrow(alltokens), \n                              ncol=length(names(dictionary)), \n                              dimnames=list(NULL, names(dictionary))))\n    #      alltokens$dictionaryWord <- \"other\"\n    for (i in 1:length(dictionary)) {\n      dictionary_word_index <- grep(paste(tolower(dictionary[[i]]), collapse=\"|\"), \n                                    alltokens$words)\n      alltokens[dictionary_word_index, 2+i] <- 1\n    }\n    alltokens$All_Words <- 1\n    dictsplit <- split(alltokens[, 3:ncol(alltokens)], alltokens$docs)\n    dictsum <- sapply(dictsplit, colSums)\n    dfm <- as.data.frame.matrix(t(dictsum))\n    # doing it this way avoids an error using rowSums if only one dictionary column\n    dfm$Non_Dictionary <- 2*dfm$All_Words - rowSums(dfm)\n    dfm <- dfm[, -(ncol(dfm)-1)]\n  }\n  \n  # re-written PN 30th June\n  if (!is.null(stopwords)) {\n    if (verbose) cat(\" removing stopwords ... \")\n    # need two separate checks because if() on a char vector gives warning\n    if (!is.character(stopwords)){\n      if (stopwords==TRUE){\n        stopwords <- stopwordsGet()\n      }\n    }\n    if (!is.character(stopwords) | !length(stopwords)>0) {\n      stop(\"stopwords must be a character vector with positive length.\")\n    }\n    if (bigram==TRUE) {\n      pat <- paste(paste0(paste0(\"-\", stopwords, \"$\"), collapse='|'), paste0(paste0(\"^\", stopwords, \"-\"), collapse='|'), sep='|')\n      dfm <- t(subset(t(dfm), !grepl(pat, colnames(dfm))))\n    } else {\n      dfm <- t(subset(t(dfm), !colnames(dfm) %in% stopwords))\n    }\n  }\n  \n  if (!is.null(addto)) {\n    if (sum(rownames(dfm) != rownames(addto)) > 0) {\n      stop(\"Cannot add to dfm: different document set.\")\n    }\n    addIndex <- which(!(colnames(addto) %in% colnames(dfm)))\n    # adjust the \"Non_Dictionary\" count for the combined object if both are dictionary-based\n    if (\"Non_Dictionary\" %in% colnames(addto) & \"Non_Dictionary\" %in% colnames(dfm)) {\n      dfm[, \"Non_Dictionary\"] <- addto[, \"Non_Dictionary\"] - rowSums(as.matrix(dfm[, -ncol(dfm)]))\n    }\n    dfm <- cbind(addto[, addIndex], dfm)\n  }\n  \n  # give the matrix austin a \"wfm\"-like record of which margin is words, which is docs\n  dfm <- as.matrix(dfm)\n  dimnames(dfm) <- list(docs = rownames(dfm), words = colnames(dfm))\n  \n  # restore original sort order\n  \n  dfm <- dfm[(1:nrow(dfm))[order(originalSortOrder)], ]\n  \n  if(verbose) cat(\" done. \\n\")\n  return(dfm)\n}\n\n\n#' Flatten a hierarchical dictionary into a list of character vectors\n#'\n#' Converts a hierarchical dictionary (a named list of named lists, ending in character \n#' vectors at the lowest level) into a flat list of character vectors.  Works like\n#' \\code{unlist(dictionary, recursive=TRUE)} except that the recursion does not go to the \n#' bottom level.\n#' \n#' Called by dfm()\n#' \n#' @param elms list to be flattened\n#' @param parent parent list name, gets built up through recursion in the same way that \\code{unlist(dictionary, recursive=TRUE)} works \n#' @param dict the bottom list of dictionary entries (\"synonyms\") passed up from recursive calls\n#' @return A dictionary flattened down one level further than the one passed\n#' @export \n#' @author Kohei Watanabe\n#' @examples \n#' dictPopulismEN <- \n#'     list(populism=c(\"elit*\", \"consensus*\", \"undemocratic*\", \"referend*\",\n#'                     \"corrupt*\", \"propagand\", \"politici*\", \"*deceit*\",\n#'                     \"*deceiv*\", \"*betray*\", \"shame*\", \"scandal*\", \"truth*\",\n#'                     \"dishonest*\", \"establishm*\", \"ruling*\"))\n#' flatten.dictionary(dictPopulismEN)\n#' \n#' hdict <- list(level1a = list(level1a1 = c(\"l1a11\", \"l1a12\"),\n#'                              level1a2 = c(\"l1a21\", \"l1a22\")),\n#'               level1b = list(level1b1 = c(\"l1b11\", \"l1b12\"),\n#'                              level1b2 = c(\"l1b21\", \"l1b22\", \"l1b23\")),\n#'               level1c = list(level1c1a = list(level1c1a1 = c(\"lowest1\", \"lowest2\")),\n#'                              level1c1b = list(level1c1b1 = c(\"lowestalone\"))))\n#' flatten.dictionary(hdict)\nflatten.dictionary <- function(elms, parent = '', dict = list()) {\n  for (self in names(elms)) {\n    elm <- elms[[self]]\n    if (parent != '') {\n      self <- paste(parent, self, sep='.')\n    }\n    # print(\"-------------------\")\n    # print (paste(\"Name\", self))\n    if (is.list(elm)) {\n      # print(\"List:\")\n      # print(names(elm))\n      dict <- flatten.dictionary(elm, self, dict)\n    } else {\n      # print(\"Words:\")\n      dict[[self]] <- elm\n      # print(dict)\n    }\n  }\n  return(dict)\n}\n\n\nmakeRegEx <- function(wildcardregex) {\n  for (i in 1:length(wildcardregex)) {\n    lengthWildCard <- nchar(wildcardregex[i])\n    # '*' wildcards at both ends, just remove them\n    if ((substr(wildcardregex[i], 1, 1)==\"*\") & substr(wildcardregex[i], lengthWildCard, lengthWildCard)==\"*\") {\n      # '*' wildcards at both ends, just remove them\n      wildcardregex[i] <- substr(wildcardregex[i], 2, lengthWildCard-1)\n    } else if (substr(wildcardregex[i], 1, 1)==\"*\") {\n      # '*' wildcard only at beginning, remove and add \"$\" to end\n      wildcardregex[i] <- paste(substr(wildcardregex[i], 2, lengthWildCard), \"$\", sep=\"\")\n    } else if (substr(wildcardregex[i], lengthWildCard, lengthWildCard)==\"*\") {\n      # '*' wildcard only at end, remove and add \"^\" to beginning\n      wildcardregex[i] <- paste(\"^\", substr(wildcardregex[i], 1, lengthWildCard-1), sep=\"\")\n    } else if (!((substr(wildcardregex[i], 1, 1)==\"*\") & substr(wildcardregex[i], lengthWildCard, lengthWildCard)==\"*\")) {\n      # change to ^word$ if no * at all, for exact match\n      wildcardregex[i] <- paste(\"^\", wildcardregex[i], \"$\", sep=\"\")\n    } else {\n      stop(\"Any wildcards except * and beginning or end of word not yet implemented.\")\n    }\n  }\n  return(wildcardregex)\n  ##\n  ## TO ADD:\n  ##   * in the middle of the word\n  ##   ? functionality\n  ##   [ab] meaning a or b\n}\n\n\n#' Trim a dfm based on a subset of features and words\n#'\n#' Returns a document by feature matrix reduced in size based on document and term frequency, and/or subsampling.\n#' \n#' @param dfm Document-feature matrix created by \\code{\\link{dfm}}\n#' @param minCount minimum feature count\n#' @param minDoc minimum number of documents in which a feature appears\n#' @param sample how many features to retain (based on random selection)\n#' @param verbose print messages\n#' @return A dfm matrix object reduced in size.\n#' @export \n#' @author Will Lowe, adapted by Ken Benoit\n#' @examples \n#' data(iebudgets)\n#' dtm <- dfm(iebudgets)\n#' dim(dtm)  # 196 docs x 13343 words\n#' dtmReduced <- dfmTrim(dtm, minCount=10, minDoc=3) # only words occuring at least 10 times and in at least 3 documents\n#' dim(dtmReduced)  # 196 docs x 3006 words\n#' dtmSampled <- dfmTrim(dtm, sample=200)  # top 200 words\n#' dim(dtmSampled)  # 196 x 200 words\ndfmTrim <- function(dfm, minCount=5, minDoc=5, sample=NULL, verbose=TRUE) {\n  nms <- names(dimnames(dfm))\n  if (!(!is.null(nms) && identical(sort(nms), c(\"docs\", \"words\")))) \n    stop(\"Function not applicable to this object\")\n  \n  mY <- dfm\n  if (names(dimnames(dfm))[2] == \"words\") \n    mY <- t(mY)\n  \n  rs1 <- which(rowSums(mY) >= minCount)\n  if (verbose)\n    cat(\"Words appearing less than\", minCount, \"times:\", (nrow(mY) - length(rs1)), \"\\n\")\n  \n  rs2 <- which(apply(mY, 1, function(x){ sum(x>0) >= minDoc } ))\n  if (verbose)\n    cat(\"Words appearing in fewer than\", minDoc, \"documents:\", (nrow(mY) - length(rs2)), \"\\n\")\n  \n  tokeep <- intersect(rs1, rs2)\n  if (length(tokeep)==0)\n    stop(\"No words left after trimming\")\n  \n  if (!is.null(sample)) {\n    if (sample > length(tokeep))\n      warning(paste('Sample size', sample, 'larger than',\n                    length(tokeep), \"already filtered from\", nrow(mY), \"so ignoring sampling request\"))\n    tokeep <- sample(tokeep, min(length(tokeep), sample))\n    if (verbose)\n      cat(\"Retaining a random sample of\", sample, \"words\\n\")\n  }\n  return(t(mY[sort(tokeep),]))\n}\n\n#' compute the tf-idf weights of a dfm\n#'\n#' Returns a matrix of tf-idf weights, as a \\link{dfm} object\n#' \n#' @param dfm Document-feature matrix created by \\code{\\link{dfm}}\n#' @param normalize whether to normalize term frequency by document totals\n#' @return A dfm matrix object where values are tf-idf weights\n#' @export \n#' @author Ken Benoit\n#' @examples \n#' data(iebudgets)\n#' dtm <- dfm(iebudgets)\n#' dtm[1:10, 100:110]\n#' tfidf(dtm)[1:10, 100:110]\n#' tfidf(dtm, normalize=FALSE)[1:10, 100:110]\ntfidf <- function(x, normalize = TRUE) {\n  idf <- log(length(docs(x))) - log(colSums(x > 0) + 1)\n  if (normalize) {\n    x <- x/rowSums(x)\n    x[is.nan(x)] <- 0\n  }\n  return(t(t(x) * idf))\n}\n\n#' normalizes the term frequencies a dfm\n#'\n#' Returns a matrix of term weights, as a \\link{dfm} object\n#' \n#' @param dfm Document-feature matrix created by \\code{\\link{dfm}}\n#' @return A dfm matrix object where values are relative term proportions within the document\n#' @export \n#' @author Ken Benoit\n#' @examples \n#' data(iebudgets)\n#' dtm <- dfm(iebudgets)\n#' dtm[1:10, 100:110]\n#' tf(dtm)[1:10, 100:110]\ntf <- function(x) {\n  return(x/rowSums(x))\n}\n\n\n#' @export\nwords.corpus <- function(corp) {\n  return(unlist(tokenize(corp)))\n}\n\n\n#' @export\nwords.dfm <- function (wfm) {\n  if (wordmargin(wfm) == 1) \n    rownames(wfm)\n  else colnames(wfm)\n}\n\n#' @export\ndocs <- function (wfm) {\n  if (wordmargin(wfm) == 1) \n    colnames(wfm)\n  else rownames(wfm)\n}\n\n#' @export\nis.wfm <- function (x) {\n  nms <- names(dimnames(x))\n  !is.null(nms) && identical(sort(nms), c(\"docs\", \"words\"))\n}\n\n#' @export\nwordmargin <- function (x) {\n  ifelse(names(dimnames(x))[1] == \"words\", 1, 2)\n}\n\n#' sort a dfm by one or more margins\n#'\n#' Sorts a \\link{dfm} by documents or words\n#' \n#' @param dfm Document-feature matrix created by \\code{\\link{dfm}}\n#' @param margin which margin to sort on \\code{words} to sort words, \\code{docs} to sort\n#' documents, and \\code{both} to sort both\n#' @param decreasing TRUE (default) if sort will be in descending order\n#' @return A sorted \\link{dfm} matrix object\n#' @export \n#' @author Ken Benoit\n#' @examples \n#' data(iebudgets)\n#' dtm <- dfm(iebudgets)\n#' dtm[, 1:10]\n#' dtm <- dfmSort(dtm, \"words\")\n#' dfmSort(dtm)[, 1:10]\n#' dfmSort(dtm, \"both\")[, 1:10]\ndfmSort <- function(x, margin = c(\"words\", \"docs\", \"both\"), decreasing=TRUE) {\n  margin <- match.arg(margin)\n  if (margin==\"words\") {\n    x <- x[, order(colSums(x), decreasing=decreasing)]\n  } else if (margin==\"docs\") {\n    x <- x[order(rowSums(x), decreasing=decreasing), ]\n  } else if (margin==\"both\") {\n    x <- x[order(rowSums(x), decreasing=decreasing), \n           order(colSums(x), decreasing=decreasing)]\n  }\n  return(x)\n}\n\n#' list the top n features in a dfm\n#'\n#' list a \"concordance\" of the top n features in a \\link{dfm} and their frequencies\n#' \n#' @param dfm Document-feature matrix created by \\code{\\link{dfm}}\n#' @param n how many of the top words should be listed; NULL means list all\n#' @param normalize return relative term frequency if TRUE\n#' @param bottom if TRUE, return the least frequent features instead of the most\n#' @return a data.frame of the frequencies of the top n most frequent features\n#' @export \n#' @author Ken Benoit\n#' @examples \n#' data(iebudgets)\n#' dtm <- dfm(iebudgets)\n#' topFeatures(dtm)\n#' topFeatures(dfm(iebudgets, stopwords=TRUE))\n#' topFeatures(dtm, 50, normalize=TRUE)\ntopFeatures <- function(x, n=20, normalize=FALSE, bottom=FALSE) {\n  x <- dfmSort(x, \"words\", decreasing=!bottom)\n  freq <- colSums(x)\n  if (normalize) freq <- freq / sum(freq)\n  return(data.frame(freq=freq[1:n]))\n}\n",
    "created" : 1408979438068.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4190526754",
    "id" : "AE6C0F8F",
    "lastKnownWriteTime" : 1409048115,
    "path" : "~/Dropbox/code/quanteda/R/dfm.R",
    "project_path" : "R/dfm.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}